{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Classification (Part 2) and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Shamith Achanta (shamith2)\n",
    "\n",
    "### Due September 16, 2019 11:59 PM\n",
    "\n",
    "**Logistics and Lab Submission**\n",
    "\n",
    "See the [course website](https://courses.engr.illinois.edu/ece365/fa2019/logisticsvvv.html). Remember that all labs count equally, despite the labs being graded from a different number of total points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What You Will Need To Know For This Lab**\n",
    "\n",
    "This lab covers a few more basic classifiers which can be used for M-ary classification:\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- Support Vector Machines\n",
    "\n",
    "as well as cross-validation, a tool for model selection and assessment.\n",
    " \n",
    "There are some problems which have short answer questions. <b>Do not write an essay -- a few (1-2) complete sentences will suffice.</b>\n",
    "\n",
    "<b>Also, be clear about your answers</b>. For example, if a question asks you \"Which classifier would you choose?\", be unequivocal about which classifier you would choose (and why); as engineers, part of your job is to make design decisions and justify them in the context of the alternatives and in the application. \n",
    "\n",
    "Remember in many applications, the end goal is not always \"run a classifier\", like in a homework problem, but is to use the output of the classifier in the context of the problem at hand (e.g. detecting spam, identifying cancer, etc.). Because of this, some of our Engineering Design-type questions are designed to get you to think about the entire design problem at a high level.\n",
    "\n",
    "\n",
    "**Warning: Do not train on your test sets. You will automatically have your score halved for a problem if you train on your test data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preamble (don't change this)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Spam Detection (90 points)\n",
    "\n",
    "In this problem, you will be constructing a crude spam detector. As you all know, when you receive an e-mail, it can be divided into one of two types: ham (useful mail, label $-1$) and spam (junk mail, label $+1$). In the [olden days](http://www.paulgraham.com/spam.html), people tried writing a bunch of rules to detect spam. However, it was quickly seen that machine learning approaches work fairly well for a little bit of work. \n",
    "\n",
    "You will be designing a spam detector by applying some of the classification techniques you learned in class to a batch of emails used to train and test [SpamAssassin](http://spamassassin.apache.org/), a leading anti-spam software package. \n",
    "\n",
    "Let the *vocabulary* of a dataset be a list of all terms occuring in a data set. So, for example, a vocabulary could be [\"cat\",\"dog\",\"chupacabra\", \"aerospace\", ...]. \n",
    "\n",
    "Our features will be based only the frequencies of terms in our vocabulary occuring in the e-mails (such an approach is called a *bag of words* approach, since we ignore the positions of the terms in the emails). The $j$-th feature is the number of times term $j$ in the vocabulary occurs in the email. If you are interested in further details on this model, you can see Chapters 6 and 13 in [Manning's Book](http://nlp.stanford.edu/IR-book/).\n",
    "\n",
    "You will use the following classifiers in this problem:\n",
    "- sklearn.naive_bayes.BernoulliNB (Naive Bayes Classifier with Bernoulli Model)\n",
    "- sklearn.naive_bayes.MultinomialNB (Naive Bayes Classifier with Multinomial Model)\n",
    "- sklearn.svm.LinearSVC (Linear Support Vector Machine)\n",
    "- sklearn.linear_model.LogisticRegression (Logistic Regression)\n",
    "- sklearn.neighbors.KNeighborsClassifier (1-Nearest Neighbor Classifier)\n",
    "\n",
    "In the context of the Bernoulli Model for Naive Bayes, scikit-learn will binarize the features by interpretting the $j$-th feature to be $1$ if the $j$-th term in the vocabulary occurs in the email and $0$ otherwise. This is a categorical Naive Bayes model, with binary features. While we did not discuss the multinomial model in class, it operates directly on the frequencies of terms in the vocabulary, and is discussed in Section 13.2 in [Manning's Book](http://nlp.stanford.edu/IR-book/) (though you do not need to read this reference). Both the Bernoulli and Multinomial models are commonly used for Naive Bayes in text classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample Ham email is:\n",
    "\n",
    "    From nic@starflung.com  Mon Jun 24 17:06:54 2002\n",
    "    Return-Path: 7910726.0.27May2002215326@mp.opensrs.net\n",
    "    Delivery-Date: Tue May 28 02:53:28 2002\n",
    "    Received: from mp.opensrs.net (mp.opensrs.net [216.40.33.45]) by\n",
    "        dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g4S1rSe14718 for\n",
    "        <zzz@spamassassin.taint.org>; Tue, 28 May 2002 02:53:28 +0100\n",
    "    Received: (from popensrs@localhost) by mp.opensrs.net (8.9.3/8.9.3) id\n",
    "        VAA04361; Mon, 27 May 2002 21:53:26 -0400\n",
    "    Message-Id: <7910726.0.27May2002215326@mp.opensrs.net>\n",
    "    Date: Mon, 27 May 2002 21:53:26 -0500 (EST)\n",
    "    From: \"Starflung NIC\" <nic@starflung.com>\n",
    "    To: <zzz@spamassassin.taint.org>\n",
    "    Subject: Automated 30 day renewal reminder 2002-05-27\n",
    "    X-Keywords: \n",
    "\n",
    "    The following domains that are registered as belonging\n",
    "    to you are due to expire within the next 60 days. If\n",
    "    you would like to renew them, please contact\n",
    "    nic@starflung.com; otherwise they will be deactivated\n",
    "    and may be registered by another.\n",
    "\n",
    "\n",
    "    Domain Name, Expiry Date\n",
    "    nutmegclothing.com, 2002-06-26\n",
    "    \n",
    "    \n",
    "A sample Spam email is: \n",
    "\n",
    "    From jjj@mymail.dk  Fri Aug 23 11:03:31 2002\n",
    "    Return-Path: <jjj@mymail.dk>\n",
    "    Delivered-To: zzzz@localhost.example.com\n",
    "    Received: from localhost (localhost [127.0.0.1])\n",
    "        by phobos.labs.example.com (Postfix) with ESMTP id 478B54415C\n",
    "        for <zzzz@localhost>; Fri, 23 Aug 2002 06:02:57 -0400 (EDT)\n",
    "    Received: from mail.webnote.net [193.120.211.219]\n",
    "        by localhost with POP3 (fetchmail-5.9.0)\n",
    "        for zzzz@localhost (single-drop); Fri, 23 Aug 2002 11:02:57 +0100 (IST)\n",
    "    Received: from smtp.easydns.com (smtp.easydns.com [205.210.42.30])\n",
    "        by webnote.net (8.9.3/8.9.3) with ESMTP id IAA08912;\n",
    "        Fri, 23 Aug 2002 08:13:36 +0100\n",
    "    From: jjj@mymail.dk\n",
    "    Received: from mymail.dk (unknown [61.97.34.233])\n",
    "        by smtp.easydns.com (Postfix) with SMTP\n",
    "        id 7484A2F85C; Fri, 23 Aug 2002 03:13:31 -0400 (EDT)\n",
    "    Reply-To: <jjj@mymail.dk>\n",
    "    Message-ID: <008c61d64eed$6184e5d5$4bc22de3@udnugg>\n",
    "    To: bbr_hooten@yahoo.com\n",
    "    Subject: HELP WANTED.  WORK FROM HOME REPS.\n",
    "    MiME-Version: 1.0\n",
    "    Content-Type: text/plain;\n",
    "        charset=\"iso-8859-1\"\n",
    "    X-Priority: 3 (Normal)\n",
    "    X-MSMail-Priority: Normal\n",
    "    X-Mailer: Microsoft Outlook, Build 10.0.2616\n",
    "    Importance: Normal\n",
    "    Date: Fri, 23 Aug 2002 03:13:31 -0400 (EDT)\n",
    "    Content-Transfer-Encoding: 8bit\n",
    "\n",
    "    Help wanted.  We are a 14 year old fortune 500 company, that is\n",
    "    growing at a tremendous rate.  We are looking for individuals who\n",
    "    want to work from home.\n",
    "\n",
    "    This is an opportunity to make an excellent income.  No experience\n",
    "    is required.  We will train you.\n",
    "\n",
    "    So if you are looking to be employed from home with a career that has\n",
    "    vast opportunities, then go:\n",
    "\n",
    "    http://www.basetel.com/wealthnow\n",
    "\n",
    "    We are looking for energetic and self motivated people.  If that is you\n",
    "    than click on the link and fill out the form, and one of our\n",
    "    employement specialist will contact you.\n",
    "\n",
    "    To be removed from our link simple go to:\n",
    "\n",
    "    http://www.basetel.com/remove.html\n",
    "\n",
    "\n",
    "    1349lmrd5-948HyhJ3622xXiM0-290VZdq6044fFvN0-799hUsU07l50\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the data. Our dataset has a bit over 9000 emails, with about 25% of them being spam. We will use 50% of them as a training set, 25% of them as a validation set and 25% of them as a test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of emails\n",
    "spamfiles=glob.glob('./Data/Spam/*')\n",
    "hamfiles=glob.glob('./Data/Ham/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will split the files into the training, validation and test sets.\n",
    "\n",
    "np.random.seed(seed=222017) # seed the RNG for repeatability\n",
    "\n",
    "fnames=np.asarray(spamfiles+hamfiles)\n",
    "nfiles=fnames.size\n",
    "labels=np.ones(nfiles)\n",
    "labels[len(spamfiles):]=-1\n",
    "\n",
    "# Randomly permute the files we have\n",
    "idx=np.random.permutation(nfiles)\n",
    "fnames=fnames[idx]\n",
    "labels=labels[idx]\n",
    "\n",
    "#Split the file names into which set they belong to\n",
    "tname=fnames[:int(nfiles/2)]\n",
    "trainlabels=labels[:int(nfiles/2)]\n",
    "vname=fnames[int(nfiles/2):int(nfiles*3/4)]\n",
    "vallabels=labels[int(nfiles/2):int(nfiles*3/4)]\n",
    "tename=fnames[int(3/4*nfiles):]\n",
    "testlabels=labels[int(3/4*nfiles):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Get our Bag of Words Features from the data\n",
    "bow = CountVectorizer(input='filename',encoding='iso-8859-1',binary=False)\n",
    "traindata=bow.fit_transform(tname)\n",
    "valdata=bow.transform(vname)\n",
    "testdata=bow.transform(tename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $100$ most and least common terms in the vocabulary are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 most common terms:  slashnull,dogma,ist,thu,not,lists,cnet,mail,wed,as,html,have,click,jmason,exmh,00,are,align,freshrpms,or,mailman,date,text,mon,message,12,postfix,type,arial,users,bgcolor,ie,rpm,linux,version,22,be,taint,your,mailto,sourceforge,admin,content,20,color,table,jm,on,aug,border,127,example,face,href,this,nbsp,gif,09,subject,10,img,src,sep,it,that,0100,spamassassin,height,esmtp,is,size,xent,fork,you,tr,www,in,list,11,br,width,received,localhost,id,of,and,org,by,with,net,for,td,http,2002,font,from,3d,to,the,com \n",
      "\n",
      "100 least common terms:  g6mn17405760,e17titx,e17tvdy,e17ueb2,e17vjs8,e17vjsf,e17w5r4,e17wchv,e17wcmr,s4tkh2qxhrdntbervcuydvpgt4frugzlf3xwvohcrdtxohcfpaziiaed0ne9lw5,e17wosd,e17wosk,e17wssb,e17titf,e17wsyl,e17xbmd,e17xd4y,e17xlhj,e17yawz,s4lyze220qd,e17yozl,e17ysm1,e17ysna,e17ysox,e17ywux,e17z5re,e17z65d,e17wved,e17tfo0,e17texc,e17stjj,e17kazn,e17kb3f,e17kb3l,e17kba2,e17kcfg,e17kkxb,e17kxx7,e17kxxd,e17lk0h,e17lzkx,e17m2xi,e17mbzo,e17mpr7,e17n4br,e17n8od,e17nmuf,e17oai5,e17owlg,e17owlz,e17pfia,e17pfih,e17r7cf,e17rqza,e17rqzi,e17s52j,e17s6q9,e17sd3a,e17zimu,e17zl6i,e18bs5u,e18ec44161,e1n_n,e1pyognhf88zoewompdrqazaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa,s42bvq,s3zy0uqn9cxgumxzswr1e,e1s_jim_mac_gearailt,e1t,e1xwdo3b1k3wvr1u6cyugmvhm1nnyssndv2knuhw4g,s3wul4rjqofkdbzdhdtzxxnb005aaaaaa,e208716f77,e208e2940b3,e20c8406ff,s3w3ibekx4my0f8afuy,s3ulb6cl,e2178f6d01a70dfbdf9c84c4dcaf58dc,e22,e22432940aa,e224536,e226e294098,e22ab2d42c,e23,e23917,e23a916f1e,s3qjh,e240,e240merc,e241b6184464107168656739bf96c6b9,e242f2940ef,e1l_,e17k4ao,e1l1o9q,e1irt,e18gf17,e18hpmg,e18ifxm,e193416fea,e1amfeffcsliuttecieokbirfye5ds7mqt6dpbmltqjmwz5kzz5qvkvkvknb0i8hihpnwqro1z3a,e1b2916f03,e1bf816efc\n"
     ]
    }
   ],
   "source": [
    "counts=np.reshape(np.asarray(np.argsort(traindata.sum(axis=0))),-1)\n",
    "vocab=np.reshape(np.asarray(bow.get_feature_names()),-1)\n",
    "print (\"100 most common terms: \" , ','.join(str(s) for s in vocab[counts[-100:]]), \"\\n\")\n",
    "print (\"100 least common terms: \" , ','.join(str(s) for s in vocab[counts[:100]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have our training data in `traindata` (with labels in `trainlabels`), validation data in `valdata` (with labels in `vallabels`) and test data in `testdata` (with labels in `testlabels`). The data is stored as a sparse scipy matrix (scipy.sparse.csr.csr_matrix), since we have a decent number of features (~100k), most of which are zero (~0.2% are non-zero), this allows storing the data in a few megabytes. Directly storing it as a numpy array (as we did in lab 1) would take around 8 gigabytes. Working with sparse data can make many algorithms run faster and use less storage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train each of the following classifiers **( 3 Points Each )**:\n",
    "- sklearn.naive_bayes.BernoulliNB (Naive Bayes Classifier with Bernoulli Model)\n",
    "- sklearn.naive_bayes.MultinomialNB (Naive Bayes Classifier with Multinomial Model)\n",
    "- sklearn.svm.LinearSVC (Linear Support Vector Machine)\n",
    "- sklearn.linear_model.LogisticRegression (Logistic Regression)\n",
    "- sklearn.neighbors.KNeighborsClassifier (as a 1-Nearest Neighbor Classifier)\n",
    "on the training data in `traindata` with corresponding labels `trainlabels`. Use the default parameters, unless otherwise noted.\n",
    "\n",
    "For each classifier, report:\n",
    "- Time it took to fit the classifier (i.e. time to perform xxx.fit(X,y)) **(1 Point Each)**\n",
    "- Training Error **( 1 Point Each)**\n",
    "\n",
    "This part of the problem has a total of **25 points**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: BernoulliNB\n",
      "Training time: 0.030487537384033203 s\n",
      "Training error: 0.03359007274283269\n",
      "\n",
      "Classifier: MultinomialNB\n",
      "Training time: 0.016047954559326172 s\n",
      "Training error: 0.019255455712451863\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LinearSVC\n",
      "Training time: 0.5862245559692383 s\n",
      "Training error: 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression\n",
      "Training time: 2.525397539138794 s\n",
      "Training error: 0.0\n",
      "\n",
      "Classifier: KNeighborsClassifier\n",
      "Training time: 0.0 s\n",
      "Training error: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "# dictionary of trained classifiers\n",
    "trained_classifiers = dict()\n",
    "\n",
    "# train each of the given classifiers on training data\n",
    "for classifier in [BernoulliNB, MultinomialNB, LinearSVC, LogisticRegression, KNeighborsClassifier]:\n",
    "    # classifer's name\n",
    "    name = classifier.__name__\n",
    "    \n",
    "    # set n_neighbors = 1 for KNeighborsClassifier (default n_neighbors = 5)\n",
    "    if(name == \"KNeighborsClassifier\"):\n",
    "        clf = classifier(n_neighbors = 1)\n",
    "    # for other classifiers, use default parameters\n",
    "    else:\n",
    "        clf = classifier()\n",
    "        \n",
    "    # computing classifier training time\n",
    "    start_time = time.time()\n",
    "    clf.fit(traindata, trainlabels)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # predictions on training data\n",
    "    predtrainlabels = clf.predict(traindata)\n",
    "    \n",
    "    # saving trained classifier\n",
    "    trained_classifiers[name] = clf\n",
    "    \n",
    "    # print results\n",
    "    print(\"Classifier: {}\".format(name))\n",
    "    print(\"Training time: {} s\".format(end_time - start_time))\n",
    "    print(\"Training error: {}\\n\".format(np.mean(trainlabels != predtrainlabels))) # 0-1 error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Naive Bayes BernoulliNB: Training time: 0.0511 s and Training error: 0.03359 or 3.359 %;\n",
    "   Naive Bayes MultinomialNB: Training time: 0.0295 s and Training error: 0.01925 or 1.925 %;\n",
    "   Linear SVC: Training time: 0.7923 s and Training error: 0.0 or 0.0 %;\n",
    "   Logistic Regression: Training time: 6.382 s and Training error: 0.0 or 0.0 %;\n",
    "   KNeighbors Classifier: Training time: 0.0187 s and Training error: 0.0 or 0.0 %]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give a justification as to why the Linear SVM and Logistic regression have their particular value of training error. **(5 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Both the Linear SVM and Logistic regression are assumed to have binomial distributions (i.e. they classify properly or don't). When we predict on the training set, the models classify the data perfectly (producing an error of 0%) because the trained models do not have to generalize, they simply classify the data according to the original training of the model.]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run each of the classifiers on the validation data **(2 Points Each)**:\n",
    "- sklearn.naive_bayes.BernoulliNB (Naive Bayes Classifier with Bernoulli Model)\n",
    "- sklearn.naive_bayes.MultiomialNB (Naive Bayes Classifier with Multiomial Model)\n",
    "- sklearn.svm.LinearSVC (Linear Support Vector Classifier)\n",
    "- sklearn.linear_model.LogisticRegression (Logistic Regression)\n",
    "- sklearn.neighbors.KNeighborsClassifier (as a 1-Nearest Neighbor Classifier)\n",
    "on the training data in `traindata` with corresponding labels `trainlabels`. Use the default parameters, unless otherwise noted.\n",
    "\n",
    "For each classifier:\n",
    "- Store the labels it predicted as \\_\\_vallabels, where \\_\\_ is BB,MB,LSVM,LR,NN respectively. **(1 Point Each)**\n",
    "- Report the Time it took to run the classifier on the data **(1 Point Each)**\n",
    "- Report Validation Error **(1 Point Each)**\n",
    "\n",
    "This part of the problem has a total of **25 points**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: BernoulliNB\n",
      "Validation time: 0.01564168930053711 s\n",
      "Validation error: 0.05477107402652974\n",
      "\n",
      "Classifier: MultinomialNB\n",
      "Validation time: 0.015620708465576172 s\n",
      "Validation error: 0.026957637997432605\n",
      "\n",
      "Classifier: LinearSVC\n",
      "Validation time: 0.0 s\n",
      "Validation error: 0.01069747539580659\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Validation time: 0.0 s\n",
      "Validation error: 0.008130081300813009\n",
      "\n",
      "Classifier: KNeighborsClassifier\n",
      "Validation time: 2.107832908630371 s\n",
      "Validation error: 0.016260162601626018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "# train each of the given classifiers on training data\n",
    "for classifier in trained_classifiers:\n",
    "    # classifier\n",
    "    clf = trained_classifiers[classifier]\n",
    "    \n",
    "    # predictions on validation data\n",
    "    # and computing classifier validation time\n",
    "    start_time = time.time()\n",
    "    predvallabels = clf.predict(valdata)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # store predicted values\n",
    "    trained_classifiers[classifier] = {'algorithm': clf, 'vallabels': predvallabels}\n",
    "    \n",
    "    # print results\n",
    "    print(\"Classifier: {}\".format(classifier))\n",
    "    print(\"Validation time: {} s\".format(end_time - start_time))\n",
    "    print(\"Validation error: {}\\n\".format(np.mean(vallabels != predvallabels))) # 0-1 error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Naive Bayes BernoulliNB: Validation time: 0.0425 s and Validation error: 0.05477 or 5.477 %;\n",
    "   Naive Bayes MultinomialNB: Validation time: 0.0123 s and Validation error: 0.02695 or 2.695 %;\n",
    "   Linear SVC: Validation time: 0.00636 s and Validation error: 0.01069 or 1.069 %;\n",
    "   Logistic Regression: Validation time: 0.00612 s and Validation error: 0.00813 or 0.813 %;\n",
    "   Linear SVC: Validation time: 3.4477 s and Validation error: 0.01626 or 1.626 %]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a more nuanced look at the type of errors made on a data set. The following function calculates a confusion matrix (Fig. 2.1 in the notes) and some statistics. You may wish to read Section 2.1.1 in the notes -- it may be helpful, but is not necessary to complete this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfMatr(truelabels,estimatedlabels,classifiername):\n",
    "    # classifiername is a string, such as 'Naive Bayes (Bernoulli)'\n",
    "    cm=np.zeros((2,2))\n",
    "    cm[0,0]=np.sum(np.logical_and(truelabels==1,estimatedlabels==1)) # True Positives\n",
    "    cm[0,1]=np.sum(np.logical_and(truelabels==-1,estimatedlabels==1)) # False Positive\n",
    "    cm[1,0]=np.sum(np.logical_and(truelabels==1,estimatedlabels==-1)) # False Negative\n",
    "    cm[1,1]=np.sum(np.logical_and(truelabels==-1,estimatedlabels==-1)) # True Negatives\n",
    "    print (\"Classifier Name: %s\"% classifiername )\n",
    "    print (\"True Positives:\", cm[0,0], \"False Positive:\", cm[0,1])\n",
    "    print (\"False Negative:\", cm[1,0], \"True Negatives:\", cm[1,1])\n",
    "    print (\"True Positive Rate : \", cm[0,0]/np.sum(truelabels==1))\n",
    "    print (\"False Positive Rate: \", cm[0,1]/np.sum(truelabels==-1))\n",
    "    print (\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run ConfMatr using the validation labels and their estimates for all the classifiers we've used in this problem (and show the corresponding results). **(5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Name: BernoulliNB\n",
      "True Positives: 490.0 False Positive: 16.0\n",
      "False Negative: 112.0 True Negatives: 1719.0\n",
      "True Positive Rate :  0.813953488372093\n",
      "False Positive Rate:  0.009221902017291067\n",
      "---\n",
      "Classifier Name: MultinomialNB\n",
      "True Positives: 549.0 False Positive: 10.0\n",
      "False Negative: 53.0 True Negatives: 1725.0\n",
      "True Positive Rate :  0.9119601328903655\n",
      "False Positive Rate:  0.005763688760806916\n",
      "---\n",
      "Classifier Name: LinearSVC\n",
      "True Positives: 594.0 False Positive: 17.0\n",
      "False Negative: 8.0 True Negatives: 1718.0\n",
      "True Positive Rate :  0.9867109634551495\n",
      "False Positive Rate:  0.009798270893371758\n",
      "---\n",
      "Classifier Name: LogisticRegression\n",
      "True Positives: 597.0 False Positive: 14.0\n",
      "False Negative: 5.0 True Negatives: 1721.0\n",
      "True Positive Rate :  0.9916943521594684\n",
      "False Positive Rate:  0.008069164265129682\n",
      "---\n",
      "Classifier Name: KNeighborsClassifier\n",
      "True Positives: 578.0 False Positive: 14.0\n",
      "False Negative: 24.0 True Negatives: 1721.0\n",
      "True Positive Rate :  0.9601328903654485\n",
      "False Positive Rate:  0.008069164265129682\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "for classifier in trained_classifiers:\n",
    "    ConfMatr(vallabels, trained_classifiers[classifier]['vallabels'], classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the True Positive Rate mean *for this problem*? What does the False Positive Rate mean *for this problem*? Do we want these quantites to be high, low or don't care? Explain using words (no equations!). **(10 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[The \"true positive rate\" for this problem means the proportion of emails that are correctly classfied as spam. The \"false positive rate\" means the proportion of emails that are incorrectly marked as spam. This is also, known as a Type I error or a false alarm. We would prefer the true positive rate to be high and the false postive rate to be low. In other words, we want spam to be marked as spam while avoiding marking potentially important emails as spam]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of this problem and knowledge of the application at hand (spam filtering), pick one of the classifiers in this problem and describe how you would use it as part of a spam filter for the University of Illinois email system. Be sure to justify your choice. **(10 points)**\n",
    "\n",
    "Note: For this problem, just sketch out a system design at a very high level -- how you would train the spam filter to deal with new threats, would you filter everyone's email jointly, etc. We're just looking for around a paragraph on how you would come up with a (very rough) engineering design using the results of this problem. You may get some inspiration from the [girls and boys](https://gmail.googleblog.com/2007/10/how-our-spam-filter-works.html) at [Gmail](https://gmail.googleblog.com/2015/07/the-mail-you-want-not-spam-you-dont.html), the [chimps at MailChimp](http://kb.mailchimp.com/delivery/spam-filters/about-spam-filters) or other places. Your answer should also include techniques you could use to improve the performance of the classifier over the baseline provided in this problem (e.g. new features, or whatever)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Based on the output of the Confusion Matrix, I would choose the Logistic Regression classifier to classify emails for the University of Illinois, because it had the highest true positive rate and one of the lowest false positive rates. I will implement this by training the classifier on commonly found words in \"spam\" emails, then, classify incoming emails using the classifier, and update the training set with potentially new \"spam\" words. Given the nature of this problem, a slightly higher false positive rate is worth a trade-off to further limit the amount of spam that reaches students and faculty.]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the classifier you selected in the previous part of the problem on the test data, and display test error and output of ConfMatr. Comment on the true/false positive rate and error as compared to that on the validation set. **(10 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression\n",
      "Test error: 0.008982035928143712\n",
      "\n",
      "Classifier Name: LogisticRegression\n",
      "True Positives: 616.0 False Positive: 17.0\n",
      "False Negative: 4.0 True Negatives: 1701.0\n",
      "True Positive Rate :  0.9935483870967742\n",
      "False Positive Rate:  0.00989522700814901\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "# classifier name\n",
    "classifier_name = 'LogisticRegression'\n",
    "\n",
    "# classifier\n",
    "clf = trained_classifiers[classifier_name]['algorithm']\n",
    "\n",
    "# prediction on test data\n",
    "predtestlabels = clf.predict(testdata)\n",
    "\n",
    "# store predicted values\n",
    "trained_classifiers[classifier_name]['testlabels'] = predtestlabels\n",
    "\n",
    "# print results\n",
    "print(\"Classifier: {}\".format(classifier_name))\n",
    "print(\"Test error: {}\\n\".format(np.mean(testlabels != predtestlabels))) # 0-1 error\n",
    "ConfMatr(testlabels, predtestlabels, classifier_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Both the true and false positive rates on the test classifier were higher, meaning that the model was more accurate in classifying spam on the test data than it was on the validation data. However, a slightly higher proportion of desirable emails were falsely classified as \"spam\". The test error for this classifier was about 0.009 or 0.9% which was roughly the same (about 0.1 % higher) as the validation error]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Problem 2: Cross-Validation (50 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which implements $5$-fold cross-validation to estimate the error of a classifier with cross-validation with the 0,1-loss for k-Nearest Neighbors (kNN). \n",
    "\n",
    "You will be given as input:\n",
    "* A (N,d) numpy.ndarray of training data, *trainData* (with N divisible by 5)\n",
    "* A length $N$ numpy.ndarray of training labels, *trainLabels*\n",
    "* A number $k$, for which cross-validated error estimates will be outputted for $1,\\ldots,k$\n",
    "\n",
    "Your output will be a vector (represented as a numpy.ndarray) *err*, such that *err[i]* is the cross-validated estimate of using i neighbors (*err* will be of length $k+1$; the zero-th component of the vector will be meaningless). \n",
    "\n",
    "In order that this problem is easier for us to grade, take your folds to be 0:N/5, N/5:2N/5, ..., 4N/5:N for cross-validation (In general, the folds should be randomly divided).\n",
    "\n",
    "Use scikit-learn's sklearn.neighbors.KNeighborsClassifier to perform the training and classification for the kNN models involved. Do not use any other features of scikit-learn, such as things from sklearn.model_selection. <b>(20 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidationkNN(trainData,trainLabels,k):\n",
    "    #Put your code here\n",
    "    # cross validated errors\n",
    "    err = np.zeros(k + 1)\n",
    "    N, d = trainData.shape\n",
    "    num_groups = 5\n",
    "    group_elem = N // num_groups\n",
    "    \n",
    "    for i in range(1, k + 1):\n",
    "        prederror = np.zeros(num_groups)\n",
    "        neigh = KNeighborsClassifier(n_neighbors=i)\n",
    "        \n",
    "        for group in range(num_groups):\n",
    "            # validation indices\n",
    "            val_idx = slice(group * group_elem, (group + 1) * group_elem)\n",
    "            mask_idx = np.zeros(N)\n",
    "            mask_idx[val_idx] = 1\n",
    "\n",
    "            # train knn classifier\n",
    "            neigh.fit(trainData[mask_idx != 1], trainLabels[mask_idx != 1])\n",
    "            # predict training labels\n",
    "            predtrainlabels = neigh.predict(trainData[val_idx])\n",
    "            # prediction error for each group\n",
    "            prederror[group] = np.mean(predtrainlabels != trainLabels[val_idx])\n",
    "            \n",
    "        # average of prediction errors of all groups\n",
    "        err[i] = np.mean(prederror)\n",
    "    \n",
    "    # return err\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will load some data (acquired from <a href=\"http://www.cs.ubc.ca/~murphyk/\">K.P. Murphy</a>'s <a href=\"https://github.com/probml/pmtk3\"> PMTK tookit</a>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem2_tmp= genfromtxt('Data/p2.csv', delimiter=',')\n",
    "\n",
    "# Randomly reorder the data\n",
    "np.random.seed(seed=2217) # seed the RNG for repeatability\n",
    "idx=np.random.permutation(problem2_tmp.shape[0])\n",
    "problem2_tmp=problem2_tmp[idx]\n",
    "\n",
    "#The training data which you will use is called \"traindata\"\n",
    "traindata=problem2_tmp[:200,:2]\n",
    "#The training labels are in \"labels\"\n",
    "trainlabels=problem2_tmp[:200,2]\n",
    "\n",
    "#The test data which you will use is called \"testdata\" with labels \"testlabels\"\n",
    "testdata=problem2_tmp[200:,:2]\n",
    "testlabels=problem2_tmp[200:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the cross-validation error versus number of neighbors for $1,\\ldots,30$ neighbors. Please label your plot. (Note: since matplotlib has already been populated, you can use *plot(x,y)* directly.) <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross Validation Error')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put your code here\n",
    "neighbors = 30\n",
    "crossvalknn = crossValidationkNN(traindata, trainlabels, neighbors)\n",
    "\n",
    "plot(np.arange(0, neighbors + 1), crossvalknn)\n",
    "\n",
    "xlim(1, neighbors)\n",
    "xlabel(\"Number of Neighbors\")\n",
    "ylabel(\"Cross Validation Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the number of neighbors which minimizes the cross-validation error. What is the cross-validation error for this number of neighbors? <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Cross Validation Error: 0.175 for k = 14 neighbors\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "min_neighbors = np.argmin(crossvalknn[1: neighbors + 1]) + 1\n",
    "print(\"Minimum Cross Validation Error: {} for k = {} neighbors\".format(crossvalknn[min_neighbors], min_neighbors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[k = 14 and Error: 0.175 or 17.5 %]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a kNN model on the whole training data using the number of neighbors you found in the previous part of the question, and apply it to the test data. Is it higher or lower than the cross-validation error you found in the last part of the problem? **(10 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error for k = 14: 0.214\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "neigh = KNeighborsClassifier(n_neighbors=min_neighbors)\n",
    "neigh.fit(traindata, trainlabels)\n",
    "predtestlabels = neigh.predict(testdata)\n",
    "\n",
    "print(\"Test Error for k = 14: {}\".format(np.mean(testlabels != predtestlabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Test Error: 0.214 or 21.4 %]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Detecting Cancer with SVMs and Logistic Regression (45 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the [Breast Cancer Wisconsin Data Set](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29) from \n",
    "W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993. \n",
    "\n",
    "The authors diagnosed people by characterizing 3 cell nuclei per person extracted from the breast (pictures [here](http://web.archive.org/web/19970225174429/http://www.cs.wisc.edu/~street/images/)), each with 10 features (for a 30-dimensional feature space):\n",
    "\n",
    "1. radius (mean of distances from center to points on the perimeter) \n",
    "\n",
    "2. texture (standard deviation of gray-scale values) \n",
    "\n",
    "3. perimeter \n",
    "\n",
    "4. area \n",
    "\n",
    "5. smoothness (local variation in radius lengths) \n",
    "\n",
    "6. compactness (perimeter^2 / area - 1.0) \n",
    "\n",
    "7. concavity (severity of concave portions of the contour) \n",
    "\n",
    "8. concave points (number of concave portions of the contour) \n",
    "\n",
    "9. symmetry \n",
    "\n",
    "10. fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "and classified the sample into one of two classes: Malignant ($+1$) or Benign ($-1$). You can read the original paper for more on what these features mean.\n",
    "\n",
    "You will be attempting to classify if a sample is Malignant or Benign using Support Vector Machines, as well as Logistic Regression. Since we don't have all that much data, we will use 10-fold cross-validation to tune our parameters for our SVMs and Logistic Regression. We use 90% of the data for training, and 10% for testing.\n",
    "\n",
    "You will be experimenting with SVMs using Gaussian RBF kernels (through sklearn.svm.SVC), linear SVMs (through sklearn.svm.LinearSVC), and Logistic Regression (sklearn.linear_model.LogisticRegression). \n",
    "\n",
    "Your model selection will be done with cross-validation via sklearn.model_selection's *cross_val_score*. This returns the accuracy for each fold, i.e. the fraction of samples classified correctly. Thus, the cross-validation error is simply 1-mean(cross_val_score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data. We will use scikit-learn's train test split function to split the data. The data is scaled for reasons outlined <a href=\"http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\">here</a>. In short, it helps avoid some numerical issues and avoids some problems with certain features which are typically large affecting the SVM optimization problem unfairly compared to features which are typically small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cancer = genfromtxt('Data/wdbc.csv', delimiter=',')\n",
    "\n",
    "np.random.seed(seed=282017) # seed the RNG for repeatability\n",
    "idx=np.random.permutation(cancer.shape[0])\n",
    "cancer=cancer[idx]\n",
    "\n",
    "cancer_features=cancer[:,1:]\n",
    "cancer_labels=cancer[:,0]\n",
    "\n",
    "#The training data is in data_train with labels label_train. \n",
    "# The test data is in data_test with labels label_test.\n",
    "data_train, data_test, label_train, label_test = train_test_split(cancer_features,cancer_labels,test_size=0.1,random_state=292017)\n",
    "\n",
    "# Rescale the training data and scale the test data correspondingly\n",
    "scaler=MinMaxScaler(feature_range=(-1,1))\n",
    "data_train=scaler.fit_transform(data_train) #Note that the scaling is determined solely via the training data!\n",
    "data_test=scaler.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The soft margin linear SVM is tuned based on a parameter $C$, which controls how much points can be violating the margin (this isn't the same $C$ as in the notes, though it serves the same function; see the [scikit-learn documentation](http://scikit-learn.org/stable/modules/svm.html#svc) for details). \n",
    "\n",
    "Use cross-validation to select a value of $C$ for a linear SVM (sklearn.svm.LinearSVC) by varying $C$ from $2^{-5},2^{-4},\\ldots,2^{15}$. \n",
    "\n",
    "Which value of $C$ would you choose, and why? What is the corresponding cross-validation error? (Note: Some C values will cause a failure to converge, which is okay.) <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 2^-2\n",
      "Cross Validation Error: 0.025339366515837014\n"
     ]
    }
   ],
   "source": [
    "#Put your code here\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# list of cross-validated errors for each C\n",
    "crossvalerr = []\n",
    "\n",
    "for c in range(-5, 16):\n",
    "    # classifier\n",
    "    svc_clf = LinearSVC(C = 2**c)\n",
    "    \n",
    "    # cross-validated score\n",
    "    crossvalscore = cross_val_score(svc_clf, data_train, label_train, cv=10)\n",
    "    \n",
    "    # crossvalscore gives accuarcy and not error\n",
    "    crossvalerr.append(1 - np.mean(crossvalscore))\n",
    "\n",
    "# c with minimum error    \n",
    "c = np.argmin(crossvalerr)\n",
    "\n",
    "# print results\n",
    "print(\"C: 2^{}\".format(c - 5))\n",
    "print(\"Cross Validation Error: {}\".format(crossvalerr[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[C: 2^-2 (0.25) and Error: 0.02534 or 2.534 %]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now experiment with using kernels in an SVM, particularly the Gaussian RBF kernel (in sklearn.svm.SVC). The SVM has two parameters to tune in this case: $C$ (as before), and $\\gamma$, which is a parameter in the RBF. \n",
    "\n",
    "Use cross-validation to select parameters $(C,\\gamma)$ by searching varying $(C,\\gamma)$ over $C=2^{-5},2^{-4},\\ldots,2^{15}$ and $\\gamma=2^{-15},\\ldots,2^{3}$ [So, you will try about 400 parameter choices]. This procedure is known as a **grid search**. Use *GridSearchCV* (see doc [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)) to perform a grid search (and you can use *clf.best\\_params\n",
    "_* to get the best parameters). Out of these, which $(C,\\gamma)$ parameters would you choose? What is the corresponding cross-validation error?\n",
    "\n",
    "We are using a fairly coarse grid for this problem, but one could use a finer grid once the rough range of good parameters is known (rather than starting with a fine grid, which would waste a lot of time). <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 2^3 and Gamma: 2^-3\n",
      "Cross Validation Error: 0.0195324283559577\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "# parameters to search\n",
    "params = {'C': [2 ** c for c in range(-5, 16)], 'gamma': [2 ** c for c in range(-15, 4)]}\n",
    "\n",
    "# classifier\n",
    "svm_clf = GridSearchCV(svm.SVC(kernel='rbf'), params, cv=10)\n",
    "svm_clf.fit(data_train, label_train)\n",
    "\n",
    "# cross validated accuracy and best parameters\n",
    "bestparams = svm_clf.best_params_\n",
    "svm_crossvalacc = svm_clf.cv_results_['mean_test_score'][np.argwhere(np.array(svm_clf.cv_results_['params']) == bestparams)][0][0]\n",
    "\n",
    "# print results\n",
    "print(\"C: 2^{} and Gamma: 2^{}\".format(int(np.log2(bestparams['C'])), int(np.log2(bestparams['gamma']))))\n",
    "print(\"Cross Validation Error: {}\".format(1 - svm_crossvalacc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[C: 2^3 (8); gamma: 2^-3 (0.125) and Error: 0.01953 or 1.953 %]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in a footnote in the notes, Logistic Regression normally has a regularizer parameter to promote stability. Scikit-learn calls this parameter $C$ (which is like $\\lambda^{-1}$ in the notes); see the [LibLinear](http://www.csie.ntu.edu.tw/~cjlin/papers/liblinear.pdf) documentation for the exact meaning of $C$. \n",
    "\n",
    "Use cross-validation to select a value of $C$ for logistic regression (sklearn.linear_model.LogisticRegression) by varying $C$ from $2^{-14},\\ldots,2^{14}$. You may optionally make use of sklearn.model_selection.GridSearchCV, or write the search by hand. \n",
    "\n",
    "Which value of $C$ would you choose? What is the corresponding cross-validation error? **(5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 2^0\n",
      "Cross Validation Error: 0.021455505279034726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\achan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#Put your code here\n",
    "# parameters to search\n",
    "params = {'C': [2 ** c for c in range(-14, 15)]}\n",
    "\n",
    "# classifier\n",
    "lr_clf = GridSearchCV(LogisticRegression(), params, cv=10)\n",
    "lr_clf.fit(data_train, label_train)\n",
    "\n",
    "# cross validated accuracy and best parameters\n",
    "bestparams = lr_clf.best_params_\n",
    "lr_crossvalacc = lr_clf.cv_results_['mean_test_score'][np.argwhere(np.array(lr_clf.cv_results_['params']) == bestparams)][0][0]\n",
    "\n",
    "# print results\n",
    "print(\"C: 2^{}\".format(int(np.log2(bestparams['C']))))\n",
    "print(\"Cross Validation Error: {}\".format(1 - lr_crossvalacc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[C: 2^0 (1) and Error: 0.02145 or 2.145 %]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the classifiers you selected thusfar for Linear SVM, SVM + Gaussian RBF and Logistic Regression, which classifier would you pick? Make sure to take into account error, the application and computational considerations. **(5 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Based on the above classifiers I would pick the radial basis function (RBF) SVM because it appears to have the smallest cross-validation error. However, the above implementation performs lots of computations (for classfying as well as searching for the best parameters) but the gain in Cross Validation accuracy appears to significant]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier selected above on the whole training set. Then, estimate the prediction error using the test set. What is your estimate of the prediction error? How does it compare to the cross-validation error?  <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: 0.017543859649122806\n"
     ]
    }
   ],
   "source": [
    "#Put your code here\n",
    "# classifier\n",
    "clf = svm.SVC(kernel='rbf', C=2**3, gamma=2**-3)\n",
    "\n",
    "# fit SVC classifier on whole training set\n",
    "clf.fit(data_train, label_train)\n",
    "\n",
    "# prediction on test data\n",
    "predtestlabels = clf.predict(data_test)\n",
    "\n",
    "# print test error\n",
    "print(\"Test Error: {}\".format(np.mean(predtestlabels != label_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Test Error: 0.01754 or 1.754 %]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think the 0,1-loss is appropriate performance measure to report, in this case? If so, why? If not, how would you measure performance? **(5 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[The 0,1-loss isn't an appropriate performance measure because in the case of SVM we are attempting to maximize the definition of the \"margin\" which is used to seperate the data. Therefore, allowing for gradation (rather than a binary measure) is a better measure of performance because it indicates how far away our data points are from a decision boundry. A better measure of performance is the hinge loss function which controls the size of the margin]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## And this concludes Lab 3! Congratulations!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
