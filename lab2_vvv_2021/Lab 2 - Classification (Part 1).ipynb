{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Classification (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due Feburary 9th, 2021 11:59 PM CST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistics and Lab Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [course website](https://courses.engr.illinois.edu/ece365/fa2019/logisticsvvv.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What You Will Need To Know For This Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab covers some basic classifiers which can be used for M-ary classification.\n",
    "\n",
    "- Bayes Classifiers\n",
    "- Linear Discriminant Analysis\n",
    "- k-Nearest Neighbors\n",
    "\n",
    "The submission procedure is provided below:\n",
    "- You will be provided with a template Python script (main.py) for this lab where you need to implement the provided functions as needed for each question. Follow the instructions provided in this Jupyter Notebook (.ipynb) to implement the required functions. **Do not change the file name or the function headers!**\n",
    "- Upload only your Python script (.py file) on Gradescope. Don't upload your datasets or Jupyter Notebook (.ipynb file).\n",
    "- Your grades and feedbacks will appear on Gradescope. The grading for the programming questions is automated using Gradescope autograder, no partial credits are given. Therefore, if you wish, you will have a chance to re-submit your code **within 72 hours** of receiving your first grade for this lab, only if you have *reasonable* submissions before the deadline (i.e. not an empty script).\n",
    "- If you re-submit, the final grade for the programming part of this lab will be calculated as .4 \\* first_grade + .6 \\* .9 \\* re-submission_grade.\n",
    "- This lab also has Multiple Choice Questions (MCQs) that are needed to be completed on Gradescope **within the deadline**.\n",
    "\n",
    "\n",
    "There are some problems which have short answer questions. They are not graded, but we are free to discuss answers to these problems. **Multiple Choice Questions (MCQs) will be graded on Gradescope!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please type all your answers in *main.py*! You only need to submit *main.py*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preamble (Don't change this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as dist\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line runs your python script that you are going to submit. **Do not change the file name!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data needed for Problems 1-3 \n",
    "\n",
    "# Read the data\n",
    "traindata_tmp= genfromtxt('train.csv', delimiter=',')\n",
    "valdata_tmp= genfromtxt('val.csv', delimiter=',')\n",
    "\n",
    "#The data which you will use to train LDA and kNN is called \"trainingdata\"\n",
    "trainingdata=traindata_tmp[:,:2]\n",
    "#The corresponding labels are in \"traininglabels\"\n",
    "traininglabels=traindata_tmp[:,2]\n",
    "\n",
    "#The data which you will use to validate LDA, kNN and the Bayes Classifier\n",
    "#is called \"valdata\"\n",
    "valdata=valdata_tmp[:,:2]\n",
    "#The corresponding labels are in \"vallabels\"\n",
    "vallabels=valdata_tmp[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some code to visualize decision regions in Problem 1 to 3; you don't need to look at this\n",
    "adp=np.vstack([trainingdata,valdata])\n",
    "xmin,xmax = adp[:,0].min()-1, adp[:,0].max()+1\n",
    "ymin,ymax = adp[:,0].min()-1, adp[:,0].max()+1\n",
    "xx, yy = np.meshgrid(np.arange(xmin, xmax, 0.05),np.arange(ymin, ymax, 0.05))\n",
    "drdata= np.c_[xx.ravel(), yy.ravel()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 : Bayes Classifiers (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will implement a Bayes classifier for the following $M$-ary classification problem:\n",
    "\n",
    "$$H_y: \\mathbf{X} \\sim \\mathcal{N}(\\mathbf{\\mu}_y,{\\sf C}) \\qquad y=0,\\ldots,M-1$$\n",
    "\n",
    "i.e. the data is a $d$-dimensional Gaussian with a common covariance matrix $\\sf C$ among all classes, but the means are different (and there is a prior among the classes). Remember, when the mean vectors, covariance matrix and prior probabilities are known, no classifier can do better than the Bayes classifier.\n",
    "\n",
    "You will write a function which takes in 4 parameters:\n",
    "* A set of data to classify (with rows as feature vectors) as a $(V,d)$ numpy.ndarray (data)\n",
    "* A M-length vector with the prior probabilities of each class as a numpy.ndarray (pi)\n",
    "* A matrix with rows giving the class means as a $(M,d)$ numpy.ndarray (means)\n",
    "* The common covariance matrix as a $(d,d)$ numpy.ndarray (cov)\n",
    "\n",
    "It will output a length $V$ numpy.ndarray of the outputs of the classifier (labels). You may not use scikit-learn or similar to implement this. Note that the class labels in this problem are $0,1,2$ (not $1,2,3$). Since Python uses zero-based indexing, this will allow you to avoid a few +1's in your code. \n",
    "\n",
    "<b>Note that there are 5 bonus points for not using loops in Problem 1.</b>\n",
    "\n",
    "Some hints:\n",
    "* If you did lab 1, exercises 5 and 6, they will get you through the bulk of this problem.\n",
    "* A non-exhaustive list of useful functions: numpy.linalg.inv, numpy.sum, numpy.log, numpy.argmax.\n",
    "* You may use <a href=\"http://docs.scipy.org/doc/numpy-1.10.1/user/basics.broadcasting.html\">broadcasting</a> to help simplify your code. The basic form you may want to use is, if you have code which says A + B where A is (n,m) and B is (m,) then numpy will automatically translate this to adding B to each row of A. \n",
    "\n",
    "\n",
    "A function prototype is provided in *main.py* <b>(10 points for correctness + 5 points for speed)</b>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will write a function which calculates the error of a classifier using the $0,1$-loss by comparing the true labels and the predicted labels. \n",
    "\n",
    "The function will take in two parameters:\n",
    "* A vector of length $N$ with the true labels as a numpy.ndarray (truelabels)\n",
    "* A vector of length $N$ with the estimated labels as a numpy.ndarray (estimatedlabels)\n",
    "\n",
    "The function will return the error (a scalar).\n",
    "\n",
    "A function prototype is provided in *main.py* <b>(5 points)</b>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will load some sample data, in the format specified above. \n",
    "We have three classes, with\n",
    "$$\\pi_0=\\frac{1}{4}, \\pi_1=\\frac{1}{4}, \\pi_2=\\frac{1}{2}$$\n",
    "\n",
    "$$\\mathbf{\\mu}_0=\\begin{bmatrix} 1 \\\\ 5\\end{bmatrix},\\mathbf{\\mu}_1=\\begin{bmatrix} 5 \\\\ 0\\end{bmatrix}, \\mathbf{\\mu}_2=\\begin{bmatrix} -2\\\\-2\\end{bmatrix} $$\n",
    "\n",
    "$$\\Sigma=\\begin{bmatrix} 5 & 1 \\\\ 1 & 5 \\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The prior information\n",
    "pi=np.array([1/4,1/4,1/2])\n",
    "means=np.array([[1,5],[5,0],[-2,-2]])\n",
    "cov=np.array([[5,1],[1,5]])\n",
    "# The data which you will use to test the classifier is called \"data\"\n",
    "data=np.copy(valdata)\n",
    "# The labels are in \"truelabels\"\n",
    "truelabels=np.copy(vallabels)\n",
    "# Create an object for Problem 1 from main.py\n",
    "q1 = Question1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the data by class. Each class will be in a different color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter(data[:,0], data[:,1], c=truelabels)\n",
    "axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line runs the classifier on the data in `data` with labels `truelabels`. It stores the predicted labels in a variable called `estimatedlabels` and prints out the classifier's error rate. Also, it runs the classifier on the data in `drdata` and store the labels outputted by the classifier into a variable called `drB` for visualization of decision regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimatedlabels = q1.bayesClassifier(data,pi,means,cov)\n",
    "print (\"The Bayes classifier error rate is %.4f\" % q1.classifierError(truelabels,estimatedlabels))\n",
    "drB = q1.bayesClassifier(drdata,pi,means,cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets visualize the output of our classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcolormesh(xx,yy,drB.reshape(xx.shape),alpha=0.1,antialiased=True,shading='auto')\n",
    "axis('tight')\n",
    "scatter(data[:,0],data[:,1],c=truelabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should observe linear boundaries between the decision regions and almost all the points are in the correct region for this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2 : Linear Discriminant Analysis (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you will implement Linear Discriminant Analysis (LDA). You will use the Bayes classifier from Problem 1 to do this. You will be given:\n",
    "* Training data feature vectors as a $(N,d)$ numpy.ndarray (trainfeat), where each row is a feature vector.\n",
    "* Training data labels as a length $N$ numpy.ndarray (trainlabel)\n",
    "\n",
    "The first function you will write will return a tuple of the estimates of the prior probabilities (as a $M$ length numpy.ndarray), means (as a $(M,d)$ numpy.ndarray) and covariance matrix (as a $(d,d)$ numpy.ndarray) in the LDA model. You may assume that labels $0,\\ldots,$trainlabel.max() exist in order to avoid some error checking. \n",
    "\n",
    "A hint:\n",
    "* You can use logical operations+slicing to index an array. For example, if you want to get all training feature vectors whose  labels are `i`, you can use `trainfeat[trainlabel==i]`\n",
    "\n",
    "A function prototype is provided in *main.py*. <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training data is in a numpy array called `trainingdata`, with corresponding labels `traininglabels`. Our validation data is in a numpy array called `valdata`, with corresponding labels `vallabels`. The data format is the same as Problem 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can visualize the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use the following code to visualize the decision regions of the classifier.\n",
    "# You don't need to look at this cell.\n",
    "\n",
    "scatter(trainingdata[:,0],trainingdata[:,1],c=traininglabels)\n",
    "axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines train the LDA classifier on the training data in `trainingdata`, and then they run the LDA classifier on the training data and the validation data. Store the predicted training labels in `esttrlabels` and the predicted labels on the validation data in `estvallabels`. Next, the errors are calculated. `drLDA` is calculated for visualization.\n",
    "\n",
    "The function call is below, but you need to fill in the corresponding functions in *main.py*. **(10 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q2 = Question2()\n",
    "lpi, lmeans, lcov = q2.trainLDA(trainingdata,traininglabels)\n",
    "print(\"The estimated priors are:\")\n",
    "print(lpi)\n",
    "print(\"The estimated means are:\")\n",
    "print(lmeans)\n",
    "print(\"The estimated covariance matrices are:\")\n",
    "print(lcov)\n",
    "print(\"\")\n",
    "esttrlabels, trerror = q2.estTrainingLabelsAndError(trainingdata,traininglabels)\n",
    "print(\"The training error for LDA is: %.4f\" % trerror)\n",
    "estvallabels, valerror = q2.estValidationLabelsAndError(trainingdata,traininglabels,valdata,vallabels)\n",
    "print(\"The validation error for LDA is: %.4f\" % valerror)\n",
    "drLDA = q1.bayesClassifier(drdata,lpi,lmeans,lcov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is generated with the distribution used in Problem 1, so your $\\pi, \\mu, {\\sf C}$ should all be pretty close to the ones given in Problem 1. If they are not close, you've done something wrong. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the performance of the classifier on the training and validation data. In this problem, both the training and validation data was generated from the distributions specified in Problem 1, so we show both the LDA classifier (which you learned from the data) and the Bayes classifier (which assumed you knew the true joint distribution of the data and the labels). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure(figsize=(8, 8)) # If this is looking a bit squished, you can change the 8 (width) and 8 (height)\n",
    "subplot(2,2,1)\n",
    "pcolormesh(xx,yy,drLDA.reshape(xx.shape),alpha=0.1,antialiased=True,shading='auto')\n",
    "axis('tight')\n",
    "scatter(trainingdata[:,0],trainingdata[:,1],c=traininglabels)\n",
    "title('Training Data (LDA)')\n",
    "subplot(2,2,2)\n",
    "pcolormesh(xx,yy,drB.reshape(xx.shape),alpha=0.1,antialiased=True,shading='auto')\n",
    "axis('tight')\n",
    "scatter(trainingdata[:,0],trainingdata[:,1],c=traininglabels)\n",
    "title('Training Data (Bayes)')\n",
    "subplot(2,2,3)\n",
    "pcolormesh(xx,yy,drLDA.reshape(xx.shape),alpha=0.1,antialiased=True,shading='auto')\n",
    "axis('tight')\n",
    "scatter(valdata[:,0],valdata[:,1],c=vallabels)\n",
    "title('Validation Data (LDA)')\n",
    "subplot(2,2,4)\n",
    "pcolormesh(xx,yy,drB.reshape(xx.shape),alpha=0.1,antialiased=True,shading='auto')\n",
    "axis('tight')\n",
    "scatter(valdata[:,0],valdata[:,1],c=vallabels)\n",
    "title('Validation Data (Bayes)')\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the points should be correctly classified in both the training and validation data. If they are not, you've done something wrong. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3: k-Nearest Neighbors + Some Short Answer Questions (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you will implement the k-Nearest Neighbors algorithm.\n",
    "\n",
    "The following imports are copied from the beginning for your benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as dist\n",
    "from scipy import stats\n",
    "q3 = Question3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your function will take:\n",
    "* Training data feature vectors as a $(N,d)$ numpy.ndarray (trainfeat), where each row is a feature vector\n",
    "* Training data labels as a length $N$ numpy.ndarray (trainlabel)\n",
    "* Test data feature vectors as a $(V,d)$ numpy.ndarray (testfeat), where each row is a feature vector\n",
    "* The value of k\n",
    "\n",
    "Use the Euclidean distance (scipy.spatial.distance.cdist) as your dissimilarity measure. Read the documentation!\n",
    "\n",
    "Your function should return a length $V$ numpy.ndarray vector of the estimated labels. This should take around 4 lines of code. Do not use the kNN implementation in scikit-learn or similar.\n",
    "\n",
    "Some functions which may be useful (read the documentation!):\n",
    "* The numpy.argpartition function can be used to find the $k$ smallest elements of an array (via slicing)\n",
    "* scipy.stats.mode can find the most common element in an array. Check the output.\n",
    "\n",
    "<b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code runs your k-Nearest Neighbors classifier with the training data in `trainingdata` and validation data in `valdata` from Problem 2, for $k=1,3,4,5$. It also shows the training and validation error rates on the data from Problem 2. <b>(5 points)</b>\n",
    "\n",
    "Note that you should be using your `q3.kNN()` function in the function definition of `q3.kNN_errors()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingError, validationError = q3.kNN_errors(trainingdata, traininglabels, valdata, vallabels)\n",
    "k_array = [1,3,4,5]\n",
    "for i in range(4):\n",
    "    print(\"Case: k =\", k_array[i])\n",
    "    print(\"Training Error:\", trainingError[i])\n",
    "    print(\"Validation Error:\", validationError[i])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The remaining code for this question is only for your visualization. It will not be graded.\n",
    "k= # Put the value of k you would choose in the variable k.\n",
    "drK=q3.kNN(trainingdata,traininglabels,drdata,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us visualize the decision boundaries of your chosen value of $k$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure(figsize=(8, 8)) # If this is looking a bit squished, you can change the 8 (width) and 8 (height)\n",
    "subplot(2,2,1)\n",
    "pcolormesh(xx,yy,drK.reshape(xx.shape),alpha=0.1,antialiased=True,shading='auto')\n",
    "axis('tight')\n",
    "scatter(trainingdata[:,0],trainingdata[:,1],c=traininglabels)\n",
    "title('Training Data (%i-NN)'%k)\n",
    "subplot(2,2,2)\n",
    "pcolormesh(xx,yy,drB.reshape(xx.shape),alpha=0.1,antialiased=True,shading='auto')\n",
    "axis('tight')\n",
    "scatter(trainingdata[:,0],trainingdata[:,1],c=traininglabels)\n",
    "title('Training Data (Bayes)')\n",
    "subplot(2,2,3)\n",
    "pcolormesh(xx,yy,drK.reshape(xx.shape),alpha=0.1,antialiased=True,shading='auto')\n",
    "axis('tight')\n",
    "scatter(valdata[:,0],valdata[:,1],c=vallabels)\n",
    "title('Validation Data (%i-NN)'%k)\n",
    "subplot(2,2,4)\n",
    "pcolormesh(xx,yy,drB.reshape(xx.shape),alpha=0.1,antialiased=True,shading='auto')\n",
    "axis('tight')\n",
    "scatter(valdata[:,0],valdata[:,1],c=vallabels)\n",
    "title('Validation Data (Bayes)')\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4: LDA and kNN using scikit-learn <b>(20 points)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, you will be using other people's libraries to implement learning algorithms. In this problem, you will become familiar with scikit-learn's implementation of LDA and kNN.\n",
    "\n",
    "First, we will load a data set of digits drawn from zip codes written on US mail. This data set was designed to help get good algorithms to sort mail by zip code automatically. It has been preprocessed a bit, with details given <a href=\"http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/zip.info.txt\">here</a>. Each feature vector consists of $16^2$ real values representing grayscale values of a 16 by 16 image of a digit. The training data has 7291 samples, while the validation data has 2007 samples. Note that this is not the same dataset built into scikit-learn -- it is much larger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading the Data\n",
    "\n",
    "#Read in the Training Data\n",
    "traindata_tmp= genfromtxt('zip.train', delimiter=' ') \n",
    "\n",
    "#The training labels are stored in \"trainlabels\", training features in \"traindata\". Rows are feature vectors.\n",
    "trainlabels=traindata_tmp[:,0]\n",
    "traindata=traindata_tmp[:,1:]\n",
    "\n",
    "#Read in the Validation Data\n",
    "valdata_tmp= genfromtxt('zip.val', delimiter=' ') \n",
    "\n",
    "#The validation labels are stored in \"vallabels\", validation features in \"valdata\". Rows are feature vectors.\n",
    "vallabels=valdata_tmp[:,0]\n",
    "valdata=valdata_tmp[:,1:]\n",
    "\n",
    "q4 = Question4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scikit-learn's sklearn.neighbors.KNeighborsClassifier to run a Nearest Neighbor classifier (1-NN) on the validation data with the provided training set. Note that KNeighborsClassifier defaults to 5-NN. \n",
    "\n",
    "Measure the time for fitting the model and classification (the %timeit feature or time() or similar will be useful). Try the different algorithms possible to fit the model (ball tree, kd-tree and brute force, and use the fastest one in your code). Make sure to calculate the error on the validation set.  <b>(5 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nnclassifier, knnvalerror, knnfitTime, knnpredTime = q4.sklearn_kNN(traindata,trainlabels,valdata,vallabels)\n",
    "print(\"kNN Validation Error is:\", knnvalerror)\n",
    "print(\"kNN fitting Time is:\", knnfitTime, \"sec\")\n",
    "print(\"kNN prediction Time is:\", knnpredTime, \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run LDA on the validation data set with scikit-learn's sklearn.discriminant_analysis.LinearDiscriminantAnalysis class. Measure the training time as well as the time used to classify the validation set. Make sure to calculate the error on the validation set.  <b>(5 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldaclassifier, ldavalerror, ldafitTime, ldapredTime = q4.sklearn_LDA(traindata,trainlabels,valdata,vallabels)\n",
    "print(\"LDA Validation Error is:\", ldavalerror)\n",
    "print(\"LDA fitting Time is:\", ldafitTime, \"sec\")\n",
    "print(\"LDA prediction Time is:\", ldapredTime, \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are a few questions for you think about to further your understanding of these classifiers. These will not be graded. You could discuss these with other students or the TAs during the office hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Based on the performance on the validation set, which algorithm would you pick (for this particular problem)? Your answer should also take into account computational resources required, error on the validation set, and the cost associated with making an error (in real life -- recall the source of the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Do you think the 0,1-loss is appropriate error measure in this case? Why or why not? How can you use domain-specific knowledge to help improve performance for this application?\n",
    "\n",
    "If you are interested in this in more detail on this problem, see O. Matan et al., \"Reading Handwritten Digits: A ZIP Code Recognition System\", IEEE Computer, Vol 25, Number 7, pp 59-63, 1992 (<a href=\"http://yann.lecun.com/exdb/publis/pdf/matan-92.pdf\">tech report version here</a>). You do not need to look at this to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And this concludes Lab 2! Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
